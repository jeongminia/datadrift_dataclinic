{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milvus ê¸°ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”© ì €ì¥\n",
    "> ğŸ”¥ Goal\n",
    ">\n",
    ">    1. KLUE/RoBERTaë¥¼ ê¸°ë°˜ìœ¼ë¡œ Text Dataë¥¼ Embeddingìœ¼ë¡œ ë³€í™˜\n",
    ">\n",
    ">    2. Milvusì— ì„ë² ë”© ë°ì´í„° ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install Milvus\n",
    "- python virtual env; activate milenv \n",
    "    - Jupyterì—ì„œ ì¸ì‹ë  ìˆ˜ ìˆë„ë¡ ipykernel ì„¤ì¹˜\n",
    "- [Milvus 2.5](https://milvus.io/docs/ko/install_standalone-docker-compose.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ³ Docker Compose êµ¬ì„± íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "!wget https://github.com/milvus-io/milvus/releases/download/v2.5.5/milvus-standalone-docker-compose.yml -O docker-compose.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ³ Milvus Container ì‹¤í–‰\n",
    "\n",
    "!sudo docker compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ”ï¸ Install PyMilvus \n",
    "\n",
    "pip install \"pymilvus[model]\" -U "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Definition\n",
    "\n",
    "ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•´ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from pymilvus import (\n",
    "    MilvusClient,\n",
    "    DataType,\n",
    "    Function,\n",
    "    FunctionType,\n",
    "    AnnSearchRequest,\n",
    "    RRFRanker,\n",
    ")\n",
    "\n",
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "\n",
    "class HybridRetriever:\n",
    "    def __init__(self, uri, collection_name=\"hybrid\", dense_embedding_function=None):\n",
    "        self.uri = uri\n",
    "        self.collection_name = collection_name\n",
    "        self.embedding_function = dense_embedding_function\n",
    "        self.use_reranker = True\n",
    "        self.use_sparse = True\n",
    "        self.client = MilvusClient(uri=uri) # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°\n",
    "\n",
    "    def build_collection(self):\n",
    "        if isinstance(self.embedding_function.dim, dict):\n",
    "            dense_dim = self.embedding_function.dim[\"dense\"]\n",
    "        else:\n",
    "            dense_dim = self.embedding_function.dim\n",
    "\n",
    "        # í† í¬ë‚˜ì´ì € ì„¤ì •\n",
    "        tokenizer_params = {\n",
    "            \"tokenizer\": \"standard\",\n",
    "            \"filter\": [\n",
    "                \"lowercase\",\n",
    "                {\n",
    "                    \"type\": \"length\",\n",
    "                    \"max\": 200,\n",
    "                },\n",
    "                {\"type\": \"stemmer\", \"language\": \"english\"},\n",
    "                {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stop_words\": [\n",
    "                        \"a\",\n",
    "                        \"an\",\n",
    "                        \"and\",\n",
    "                        \"are\",\n",
    "                        \"as\",\n",
    "                        \"at\",\n",
    "                        \"be\",\n",
    "                        \"but\",\n",
    "                        \"by\",\n",
    "                        \"for\",\n",
    "                        \"if\",\n",
    "                        \"in\",\n",
    "                        \"into\",\n",
    "                        \"is\",\n",
    "                        \"it\",\n",
    "                        \"no\",\n",
    "                        \"not\",\n",
    "                        \"of\",\n",
    "                        \"on\",\n",
    "                        \"or\",\n",
    "                        \"such\",\n",
    "                        \"that\",\n",
    "                        \"the\",\n",
    "                        \"their\",\n",
    "                        \"then\",\n",
    "                        \"there\",\n",
    "                        \"these\",\n",
    "                        \"they\",\n",
    "                        \"this\",\n",
    "                        \"to\",\n",
    "                        \"was\",\n",
    "                        \"will\",\n",
    "                        \"with\",\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "        \n",
    "        # Milvus ì»¬ë ‰ì…˜ ìŠ¤í‚¤ë§ˆ ìƒì„±\n",
    "        schema = MilvusClient.create_schema()\n",
    "        schema.add_field(\n",
    "            field_name=\"pk\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            is_primary=True,\n",
    "            auto_id=True,\n",
    "            max_length=100,\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"content\",\n",
    "            datatype=DataType.VARCHAR,\n",
    "            max_length=65535,\n",
    "            analyzer_params=tokenizer_params,\n",
    "            enable_match=True,\n",
    "            enable_analyzer=True,\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"sparse_vector\", datatype=DataType.SPARSE_FLOAT_VECTOR\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"dense_vector\", datatype=DataType.FLOAT_VECTOR, dim=dense_dim\n",
    "        )\n",
    "        schema.add_field(\n",
    "            field_name=\"original_uuid\", datatype=DataType.VARCHAR, max_length=128\n",
    "        )\n",
    "        schema.add_field(field_name=\"doc_id\", datatype=DataType.VARCHAR, max_length=64)\n",
    "        schema.add_field(\n",
    "            field_name=\"chunk_id\", datatype=DataType.VARCHAR, max_length=64\n",
    "        ),\n",
    "        schema.add_field(field_name=\"original_index\", datatype=DataType.INT32)\n",
    "\n",
    "        # ìŠ¤ì½”ì–´ ì €ì¥\n",
    "        functions = Function(\n",
    "            name=\"bm25\",\n",
    "            function_type=FunctionType.BM25,\n",
    "            input_field_names=[\"content\"],\n",
    "            output_field_names=\"sparse_vector\",\n",
    "        )\n",
    "\n",
    "        schema.add_function(functions)\n",
    "\n",
    "        index_params = MilvusClient.prepare_index_params()\n",
    "        index_params.add_index(\n",
    "            field_name=\"sparse_vector\",\n",
    "            index_type=\"SPARSE_INVERTED_INDEX\",\n",
    "            metric_type=\"BM25\",\n",
    "        )\n",
    "        index_params.add_index(\n",
    "            field_name=\"dense_vector\", index_type=\"FLAT\", metric_type=\"IP\"\n",
    "        )\n",
    "\n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            schema=schema,\n",
    "            index_params=index_params,\n",
    "        )\n",
    "\n",
    "    # ë°ì´í„° ì‚½ì…\n",
    "    def insert_data(self, chunk, metadata):\n",
    "        embedding = self.embedding_function([chunk])\n",
    "        if isinstance(embedding, dict) and \"dense\" in embedding:\n",
    "            dense_vec = embedding[\"dense\"][0]\n",
    "        else:\n",
    "            dense_vec = embedding[0]\n",
    "        self.client.insert(\n",
    "            self.collection_name, {\"dense_vector\": dense_vec, **metadata}\n",
    "        )\n",
    "\n",
    "    # ê²€ìƒ‰ ê¸°ëŠ¥\n",
    "    def search(self, query: str, k: int = 20, mode=\"hybrid\"):\n",
    "\n",
    "        output_fields = [\n",
    "            \"content\",\n",
    "            \"original_uuid\",\n",
    "            \"doc_id\",\n",
    "            \"chunk_id\",\n",
    "            \"original_index\",\n",
    "        ]\n",
    "        if mode in [\"dense\", \"hybrid\"]:\n",
    "            embedding = self.embedding_function([query])\n",
    "            if isinstance(embedding, dict) and \"dense\" in embedding:\n",
    "                dense_vec = embedding[\"dense\"][0]\n",
    "            else:\n",
    "                dense_vec = embedding[0]\n",
    "\n",
    "        if mode == \"sparse\":\n",
    "            results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                data=[query],\n",
    "                anns_field=\"sparse_vector\",\n",
    "                limit=k,\n",
    "                output_fields=output_fields,\n",
    "            )\n",
    "        elif mode == \"dense\":\n",
    "            results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                data=[dense_vec],\n",
    "                anns_field=\"dense_vector\",\n",
    "                limit=k,\n",
    "                output_fields=output_fields,\n",
    "            )\n",
    "        elif mode == \"hybrid\":\n",
    "            full_text_search_params = {\"metric_type\": \"BM25\"}\n",
    "            full_text_search_req = AnnSearchRequest(\n",
    "                [query], \"sparse_vector\", full_text_search_params, limit=k\n",
    "            )\n",
    "\n",
    "            dense_search_params = {\"metric_type\": \"IP\"}\n",
    "            dense_req = AnnSearchRequest(\n",
    "                [dense_vec], \"dense_vector\", dense_search_params, limit=k\n",
    "            )\n",
    "\n",
    "            results = self.client.hybrid_search(\n",
    "                self.collection_name,\n",
    "                [full_text_search_req, dense_req],\n",
    "                ranker=RRFRanker(),\n",
    "                limit=k,\n",
    "                output_fields=output_fields,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode\")\n",
    "        return [\n",
    "            {\n",
    "                \"doc_id\": doc[\"entity\"][\"doc_id\"],\n",
    "                \"chunk_id\": doc[\"entity\"][\"chunk_id\"],\n",
    "                \"content\": doc[\"entity\"][\"content\"],\n",
    "                \"score\": doc[\"distance\"],\n",
    "            }\n",
    "            for doc in results[0]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milvus ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n",
    "- BM25 ê¸°ë°˜ sparse vector ê²€ìƒ‰\n",
    "- DL ê¸°ë°˜ ì„ë² ë”© ê²€ìƒ‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Embedding Vector \n",
    "\n",
    "ë²•ë¥  ë°ì´í„° ì—…ë¡œë“œ ì—†ì´ Milvusë§Œ í…ŒìŠ¤íŠ¸\n",
    "- ì €ì¥ëœ ë°ì´í„° ê²€ìƒ‰ ë° ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "MODEL_NAME = \"klue/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device) \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data in Milvus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [create index](https://milvus.io/api-reference/pymilvus/v2.3.x/MilvusClient/Management/create_index.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "\n",
    "client = MilvusClient(uri=\"http://localhost:19530\")\n",
    "\n",
    "collection_name = \"klue_roberta_embeddings\"\n",
    "\n",
    "# ì»¬ë™ì…˜ ìƒì„±\n",
    "schema = MilvusClient.create_schema()\n",
    "schema.add_field(\"id\", DataType.INT64, is_primary=True, auto_id=True)\n",
    "schema.add_field(\"content\", DataType.VARCHAR, max_length=1024)  # ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥\n",
    "schema.add_field(\"vector\", DataType.FLOAT_VECTOR, dim=768)  # KLUE/RoBERTa ì„ë² ë”© ì €ì¥\n",
    "\n",
    "client.create_collection(collection_name=collection_name, schema=schema)\n",
    "\n",
    "# ë²¡í„° í•„ë“œì— ëŒ€í•œ ì¸ë±ìŠ¤ ìƒì„±\n",
    "index_params = client.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"vector\",\n",
    "    index_type=\"IVF_FLAT\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"nlist\": 128}\n",
    ")\n",
    "client.create_index(collection_name, index_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"í•œêµ­ì˜ ì¸ê³µì§€ëŠ¥ ì—°êµ¬ëŠ” ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"MilvusëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\",\n",
    "    \"ë¡œë´‡ ê³µí•™ê³¼ ë”¥ëŸ¬ë‹ì€ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ë°ì´í„° ë³€í™˜ ë° Milvus ì‚½ì…\n",
    "for text in data:\n",
    "    embedding = get_embedding(text) \n",
    "    client.insert(collection_name, [{\"content\": text, \"vector\": embedding.tolist()}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['klue_roberta_embeddings']\n"
     ]
    }
   ],
   "source": [
    "# Milvusì— ì €ì¥ëœ ëª¨ë“  ì»¬ë ‰ì…˜ í™•ì¸\n",
    "print(client.list_collections())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collection_name': 'klue_roberta_embeddings', 'auto_id': True, 'num_shards': 1, 'description': '', 'fields': [{'field_id': 100, 'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 101, 'name': 'content', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 1024}}, {'field_id': 102, 'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 456592164736288327, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': False, 'created_timestamp': 456610227358269446}\n",
      "['vector']\n"
     ]
    }
   ],
   "source": [
    "# Vector DB ê²€ìƒ‰ ìˆ˜í–‰ì„ ìœ„í•´ ì¸ë±ìŠ¤ ìƒì„± ìœ ë¬´ íŒŒì•…\n",
    "print(client.describe_collection(collection_name))\n",
    "print(client.list_indexes(collection_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ í•œêµ­ì˜ ì¸ê³µì§€ëŠ¥ ì—°êµ¬ëŠ” ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„: 1.2914175987243652)\n",
      "ğŸ“Œ í•œêµ­ì˜ ì¸ê³µì§€ëŠ¥ ì—°êµ¬ëŠ” ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„: 1.2914175987243652)\n",
      "ğŸ“Œ ë¡œë´‡ ê³µí•™ê³¼ ë”¥ëŸ¬ë‹ì€ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„: 1.7175631523132324)\n"
     ]
    }
   ],
   "source": [
    "# ì»¬ë ‰ì…˜ ë¡œë“œ\n",
    "client.load_collection(collection_name)\n",
    "\n",
    "query = \"AI ì—°êµ¬ê°€ ë¹ ë¥´ê²Œ ì§„í–‰ ì¤‘ì´ë‹¤.\"\n",
    "query_vector = get_embedding(query) \n",
    "\n",
    "# Milvusì—ì„œ ê²€ìƒ‰\n",
    "results = client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=[query_vector],\n",
    "    anns_field=\"vector\",\n",
    "    limit=3, \n",
    "    output_fields=[\"content\"]\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "for doc in results[0]:\n",
    "    print(f\"ğŸ“Œ {doc['entity']['content']} (ìœ ì‚¬ë„: {doc['distance']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Streamlit Dashboard ìµœì í™” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
