import pandas as pd
import pdfkit
import streamlit as st
import os
import json
from pymilvus import utility, Collection, connections

# Import utils from parent directory
try:
    from ..utils import gen_summarization
except ImportError:
    # Fallback for standalone execution
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from utils import gen_summarization

@st.cache_data(ttl=1800)
def load_metadata_from_milvus(collection_name):
    """Milvus DBì—ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    try:
        connections.connect("default", host="localhost", port="19530")
        
        if not utility.has_collection(collection_name):
            return None
            
        collection = Collection(name=collection_name)
        collection.load()
        
        results = collection.query(
            expr="set_type == 'metadata'",
            output_fields=["dataset_name", "summary_dict", "data_previews", "class_dist_path", 
                          "doc_len_path", "doc_len_table", "wordcloud_path"],
            limit=1
        )
        
        if not results:
            return None
            
        metadata = results[0]
        
        # JSON í•„ë“œ íŒŒì‹± - ë” ê°•ë ¥í•œ íŒŒì‹±
        if metadata.get('summary_dict'):
            try:
                if isinstance(metadata['summary_dict'], str):
                    metadata['summary_dict'] = json.loads(metadata['summary_dict'])
                # ì´ë¯¸ dictì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                if not isinstance(metadata['summary_dict'], dict):
                    metadata['summary_dict'] = {}
            except:
                metadata['summary_dict'] = {}
        else:
            metadata['summary_dict'] = {}
            
        # data_previews íŒŒì‹± ì¶”ê°€
        if metadata.get('data_previews'):
            try:
                if isinstance(metadata['data_previews'], str):
                    metadata['data_previews'] = json.loads(metadata['data_previews'])
                if not isinstance(metadata['data_previews'], dict):
                    metadata['data_previews'] = {}
            except:
                metadata['data_previews'] = {}
        else:
            metadata['data_previews'] = {}
            
        if metadata.get('doc_len_table'):
            try:
                if isinstance(metadata['doc_len_table'], str):
                    metadata['doc_len_table'] = json.loads(metadata['doc_len_table'])
                # ì´ë¯¸ listë‚˜ dictì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            except:
                pass
        
        return metadata
        
    except Exception as e:
        st.error(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def get_metadata_from_milvus(dataset_name=None):
    """Milvusì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜"""
    if not dataset_name:
        dataset_name = 'Dataset'
    
    try:
        connections.connect("default", host="localhost", port="19530")
        collections = utility.list_collections()
        
        # dataset_nameê³¼ ì¼ì¹˜í•˜ëŠ” ì»¬ë ‰ì…˜ ì°¾ê¸°
        for collection_name in collections:
            metadata = load_metadata_from_milvus(collection_name)
            if metadata and (metadata.get('dataset_name') == dataset_name or collection_name == dataset_name):
                return metadata
        
        # ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ì²« ë²ˆì§¸ ì»¬ë ‰ì…˜ ì‚¬ìš©
        if collections:
            return load_metadata_from_milvus(collections[0])
            
    except Exception as e:
        st.error(f"Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
        return None
    
    return None

def generate_html_from_session(dataset_name=None):
    """Milvusì—ì„œ ì§ì ‘ HTML ìƒì„± (session_state ì‚¬ìš© ì•ˆ í•¨)"""
    metadata = get_metadata_from_milvus(dataset_name)
    
    if not metadata:
        return f"<html><body><h1>No metadata found for {dataset_name or 'Dataset'}</h1></body></html>"
    
    html_parts = []
    html_parts.append(f"<h1>{metadata.get('dataset_name', dataset_name or 'Dataset')} Dataset Report</h1>")

    if metadata.get("data_previews"):
        data_previews = metadata["data_previews"]
        # ë¬¸ìì—´ì¸ ê²½ìš° JSON íŒŒì‹±
        if isinstance(data_previews, str):
            try:
                data_previews = json.loads(data_previews)
            except:
                data_previews = {}
        
        for set_name, set_info in data_previews.items():
                html_parts.append(f"<h2>{set_name.capitalize()} Dataset</h2>")
                
                # ë°ì´í„°ì…‹ í†µê³„ ì •ë³´
                total_rows = set_info.get("total_rows", 0)
                columns = set_info.get("columns", [])
                html_parts.append(f"<p><strong>Total Rows:</strong> {total_rows}</p>")
                html_parts.append(f"<p><strong>Columns:</strong> {len(columns)} ({', '.join(columns)})</p>")
                
                # ë¯¸ë¦¬ë³´ê¸° í…Œì´ë¸”
                html_parts.append("<h3>Preview</h3>")
                preview_data = set_info.get("data", [])
                
                if preview_data:
                    html_parts.append('<table border="1" style="border-collapse: collapse; width: 100%;">')
                    
                    # í—¤ë”
                    if preview_data:
                        headers = list(preview_data[0].keys())
                        html_parts.append("<thead><tr>")
                        html_parts.append("<th>Index</th>")  # ì¸ë±ìŠ¤ ì»¬ëŸ¼
                        for header in headers:
                            html_parts.append(f"<th>{header}</th>")
                        html_parts.append("</tr></thead>")
                        
                        # ë°ì´í„° í–‰ë“¤ (ìµœëŒ€ 10ê°œ)
                        html_parts.append("<tbody>")
                        for i, row in enumerate(preview_data):
                            html_parts.append("<tr>")
                            html_parts.append(f"<td>{i+1}</td>")  # ì¸ë±ìŠ¤
                            for header in headers:
                                value = str(row.get(header, ""))
                                # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (100ìë¡œ ì œí•œ)
                                if len(value) > 100:
                                    value = value[:97] + "..."
                                html_parts.append(f"<td>{value}</td>")
                            html_parts.append("</tr>")
                        html_parts.append("</tbody>")
                    
                    html_parts.append("</table>")
                else:
                    html_parts.append("<p><em>ë¯¸ë¦¬ë³´ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.</em></p>")
                
                html_parts.append("<br>")  # ì„¹ì…˜ êµ¬ë¶„

    # Milvusì—ì„œ ì§ì ‘ summary_dict ì‚¬ìš©
    summary_dict = metadata.get('summary_dict', {})
    
    # summary_dictê°€ dictì¸ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬
    if not isinstance(summary_dict, dict):
        summary_dict = {}
    
    for name, summary in summary_dict.items():
        html_parts.append(f"<h2>{name} Dataset</h2>")
        
        # Preview ì²˜ë¦¬
        if 'preview' in summary:
            html_parts.append("<h3>Preview</h3>")
            try:
                if hasattr(summary["preview"], 'to_html'):
                    html_parts.append(summary["preview"].to_html(index=False))
                elif isinstance(summary["preview"], list):
                    df = pd.DataFrame(summary["preview"])
                    html_parts.append(df.to_html(index=False))
                else:
                    html_parts.append(f"<p>{summary['preview']}</p>")
            except:
                html_parts.append(f"<p>{summary['preview']}</p>")

        # Description ì²˜ë¦¬
        if 'description' in summary:
            html_parts.append("<h3>Description</h3>")
            try:
                if hasattr(summary["description"], 'to_html'):
                    html_parts.append(summary["description"].to_html(index=False))
                elif isinstance(summary["description"], list):
                    df = pd.DataFrame(summary["description"])
                    html_parts.append(df.to_html(index=False))
                else:
                    html_parts.append(f"<p>{summary['description']}</p>")
            except:
                html_parts.append(f"<p>{summary['description']}</p>")

        # Info ì²˜ë¦¬
        if 'info' in summary:
            html_parts.append("<h3>Info</h3>")
            try:
                if hasattr(summary["info"], 'to_html'):
                    html_parts.append(summary["info"].to_html(index=False))
                elif isinstance(summary["info"], list):
                    df = pd.DataFrame(summary["info"])
                    html_parts.append(df.to_html(index=False))
                else:
                    html_parts.append(f"<p>{summary['info']}</p>")
            except:
                html_parts.append(f"<p>{summary['info']}</p>")

    html_parts.append("<hr><h2>Visualizations</h2>")

    # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì²˜ë¦¬ - Milvus ë°ì´í„° ì§ì ‘ ì‚¬ìš©
    if metadata.get("class_dist_path") and os.path.exists(metadata["class_dist_path"]):
        abs_path = os.path.abspath(metadata["class_dist_path"])
        html_parts.append(f"<h3>Class Distribution</h3><img src='file://{abs_path}' width='800'><br><br>")

    if metadata.get("doc_len_path") and os.path.exists(metadata["doc_len_path"]):
        abs_path = os.path.abspath(metadata["doc_len_path"])
        html_parts.append(f"<h3>Document Length Distribution</h3><img src='file://{abs_path}' width='800'><br><br>")

    if metadata.get("doc_len_table"):
        doc_len_table = metadata["doc_len_table"]
        if isinstance(doc_len_table, str):
            html_parts.append(doc_len_table)
        elif isinstance(doc_len_table, list):
            try:
                df = pd.DataFrame(doc_len_table)
                html_parts.append("<h3>Document Length Statistics</h3>")
                html_parts.append(df.to_html(index=False))
            except:
                html_parts.append(f"<p>{doc_len_table}</p>")

    if metadata.get("wordcloud_path") and os.path.exists(metadata["wordcloud_path"]):
        abs_path = os.path.abspath(metadata["wordcloud_path"])
        html_parts.append(f"<h3>Word Cloud</h3><img src='file://{abs_path}' width='900'><br><br>")

    html_template = f"""
    <html>
        <head>
            <meta charset="utf-8">
            <style>
                body {{
                    font-family: Arial, sans-serif;
                    padding: 30px;
                }}
                h1 {{ font-size: 28px; }}
                h2 {{ font-size: 22px; margin-top: 40px; }}
                h3 {{ font-size: 18px; margin-top: 25px; }}
                table {{
                    border-collapse: collapse;
                    width: 100%;
                    margin-bottom: 20px;
                    font-size: 13px;
                }}
                th, td {{
                    border: 1px solid #ccc;
                    padding: 6px;
                    text-align: left;
                }}
                th {{ background-color: #f5f5f5; }}
                img {{
                    margin-top: 10px;
                    margin-bottom: 20px;
                }}
                .comment-box {{
                    background-color: #f4f4f4;
                    padding: 15px;
                    margin: 10px 0 30px 0;
                    border-radius: 8px;
                }}
                ul {{
                    margin: 0;
                    padding-left: 20px;
                }}
                li {{
                    margin-bottom: 6px;
                }}
            </style>
        </head>
        <body>
            {''.join(html_parts)}
        </body>
    </html>
    """
    return html_template

def render():
    # dataset_nameì„ session_stateë‚˜ ê¸°ë³¸ê°’ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    dataset_name = st.session_state.get('dataset_name', 'Dataset')
    
    # Milvusì—ì„œ ë©”íƒ€ë°ì´í„° í™•ì¸
    metadata = get_metadata_from_milvus(dataset_name)
    if not metadata:
        st.error(f"No metadata found in Milvus for dataset: {dataset_name}")
        return

    root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    reports_dir = os.path.join(root_dir, "reports")
    os.makedirs(reports_dir, exist_ok=True)

    html_out = generate_html_from_session(dataset_name)
    html_path = os.path.join(reports_dir, f"{dataset_name}_report.html")
    pdf_path = os.path.join(reports_dir, f"{dataset_name}_report.pdf")

    with open(html_path, "w", encoding="utf-8") as f:
        f.write(html_out)

    try:
        config = pdfkit.configuration(wkhtmltopdf="/usr/bin/wkhtmltopdf")  # í•„ìš” ì‹œ ìˆ˜ì •
        options = {
            'enable-local-file-access': None
        }
        pdfkit.from_file(html_path, pdf_path, configuration=config, options=options)

        with open(pdf_path, "rb") as f:
            st.download_button(
                label="ğŸ“¥ Download Dataset Report (PDF)",
                data=f,
                file_name=f"{dataset_name}_report.pdf",
                mime="application/pdf"
            )
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")