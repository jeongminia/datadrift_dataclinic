# rag_engine.py
import os
import streamlit as st
# pdf loader + split
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
# docs embedding and vectorstore
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
# retriever
# LLM ì—°ê²°, QA chain êµ¬ì„±
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

# ========== RAG ê´€ë ¨ ìœ í‹¸ë¦¬í‹° ==========
@st.cache_resource
def load_drift_knowledge_base():
    """ë“œë¦¬í”„íŠ¸ ê¸°ìˆ  ë¬¸ì„œë¥¼ FAISS ë²¡í„° DBë¡œ ë¡œë“œ (LangChain í™œìš©)"""
    pdf_path = "pdf_db/datadrift_tech_docs.pdf"
    
    if not os.path.exists(pdf_path):
        st.warning(f"ë“œë¦¬í”„íŠ¸ ê¸°ìˆ  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return None, None
    
    try:
        # 1. PDF ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¶„í• 
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()
        
        # 2. í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        chunks = text_splitter.split_documents(documents)
        
        # 3. HuggingFace ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # 4. FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = FAISS.from_documents(chunks, embeddings)
        
        # 5. Ollama LLM ì„¤ì •
        llm = Ollama(
            model="hyperclovax-seed-text-instruct-1.5B",
            temperature=0.7
        )
        
        return vectorstore, llm
        
    except Exception as e:
        st.error(f"ë“œë¦¬í”„íŠ¸ ì§€ì‹ ë² ì´ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None



def search_drift_knowledge(query: str, top_k: int = 3):
    """ë“œë¦¬í”„íŠ¸ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ (LangChain í™œìš©)"""
    vectorstore, llm = load_drift_knowledge_base()
    
    if not all([vectorstore, llm]):
        return []
    
    try:
        # ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
        relevant_docs = vectorstore.similarity_search(query, k=top_k)
        
        # ë¬¸ì„œ ë‚´ìš©ë§Œ ì¶”ì¶œ
        relevant_chunks = [doc.page_content for doc in relevant_docs]
        
        return relevant_chunks
        
    except Exception as e:
        st.error(f"ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def generate_llm_drift_explanation(dataset_name: str) -> str:
    """Ollama LLMì„ í™œìš©í•œ ë“œë¦¬í”„íŠ¸ ê²°ê³¼ í•´ì„¤ ìƒì„±"""
    
    # 1. í˜„ì¬ ë“œë¦¬í”„íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
    drift_summary = st.session_state.get('drift_score_summary', '')
    
    # ì„ë² ë”© ì •ë³´ ìˆ˜ì§‘ (utils.py ì˜ì¡´ì„± ì œê±°)
    embedding_info = {}
    for key in ['train_embeddings', 'valid_embeddings', 'test_embeddings']:
        embeddings = st.session_state.get(key)
        if embeddings is not None:
            embedding_info[key] = embeddings.shape
    
    pca_dim = st.session_state.get('pca_selected_dim')
    if pca_dim:
        embedding_info['pca_selected_dim'] = pca_dim
    
    if not drift_summary:
        return ''
    
    # 2. ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
    search_queries = [
        f"MMD Wasserstein KL divergence interpretation",
        f"data drift analysis embedding",
        "drift detection threshold explanation",
        f"PCA dimension reduction drift analysis"
    ]
    
    # 3. ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
    knowledge_context = []
    for query in search_queries:
        relevant_chunks = search_drift_knowledge(query, top_k=2)
        knowledge_context.extend(relevant_chunks)
    
    # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
    knowledge_context = list(set(knowledge_context))[:3]  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
    
    # 4. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context_text = "\n\n".join(knowledge_context)
    
    embedding_info_text = ""
    for key, shape in embedding_info.items():
        if key == 'pca_selected_dim':
            embedding_info_text += f"PCA ì°¨ì›: {shape}\n"
        else:
            embedding_info_text += f"{key}: {shape}\n"
    
    # 5. Ollamaìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt_template = PromptTemplate(
        input_variables=["dataset_name", "embedding_info", "drift_summary", "context"],
        template="""ë‹¹ì‹ ì€ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë“œë¦¬í”„íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ í•´ì„¤í•´ì£¼ì„¸ìš”.

                    ë°ì´í„°ì…‹ ì •ë³´:
                    - ì´ë¦„: {dataset_name}
                    - {embedding_info}

                    ë“œë¦¬í”„íŠ¸ ë¶„ì„ ê²°ê³¼:
                    {drift_summary}

                    ì°¸ê³  ì§€ì‹:
                    {context}

                    ë‹¤ìŒ ìˆœì„œë¡œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:
                    1. ê° ë“œë¦¬í”„íŠ¸ ë©”íŠ¸ë¦­ì˜ ì˜ë¯¸ì™€ í˜„ì¬ ìˆ˜ì¹˜ í•´ì„
                    2. ì „ì²´ì ì¸ ë“œë¦¬í”„íŠ¸ ìƒí™© í‰ê°€
                    3. ê¶Œì¥ì‚¬í•­

                    500ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
    )
    
    # 6. Ollama LLM í˜¸ì¶œ
    try:
        vectorstore, llm = load_drift_knowledge_base()
        
        if not llm:
            return generate_fallback_explanation()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        formatted_prompt = prompt_template.format(
            dataset_name=dataset_name,
            embedding_info=embedding_info_text,
            drift_summary=drift_summary,
            context=context_text
        )
        
        # LLM í˜¸ì¶œ
        explanation = llm.invoke(formatted_prompt)
        
        # HTML í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        return f"""
        <div class="comment-box" style="background-color: #e8f5e8; border-left: 4px solid #28a745;">
            <h4>ğŸ¤– AI ë“œë¦¬í”„íŠ¸ ë¶„ì„ í•´ì„¤</h4>
            <p style="margin-top: 10px; line-height: 1.6;">{explanation}</p>
            <small style="color: #6c757d; font-style: italic;">
                * ì´ í•´ì„¤ì€ ë¡œì»¬ AI(Ollama)ê°€ ê¸°ìˆ  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±í•œ ê²ƒì…ë‹ˆë‹¤.
            </small>
        </div>
        """
        
    except Exception as e:
        st.warning(f"AI í•´ì„¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return generate_fallback_explanation()

def generate_fallback_explanation() -> str:
    """LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í•´ì„¤ ì œê³µ"""
    return f"""
    <div class="comment-box" style="background-color: #fff3cd; border-left: 4px solid #ffc107;">
        <h4>âš ï¸ AI í•´ì„¤ ìƒì„± ë¶ˆê°€</h4>
        <p>í˜„ì¬ AI í•´ì„¤ ì„œë¹„ìŠ¤(Ollama)ë¥¼ ì´ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ê¸°ë³¸ ê°€ì´ë“œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”:</p>
        <ul>
            <li><strong>MMD, Wasserstein Distance</strong>: ë‚®ì„ìˆ˜ë¡ ë‘ ë°ì´í„°ì…‹ì´ ìœ ì‚¬í•¨</li>
            <li><strong>KL Divergence, JensenShannon</strong>: 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë¶„í¬ê°€ ìœ ì‚¬í•¨</li>
            <li><strong>drift = False</strong>: ë°ì´í„° ë¶„í¬ê°€ ì•ˆì •ì </li>
            <li><strong>drift = True</strong>: ë°ì´í„° ë¶„í¬ ë³€í™” ê°ì§€ë¨</li>
        </ul>
    </div>
    """