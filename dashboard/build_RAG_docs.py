import os
import re
import streamlit as st
# pdf loader + split
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
# docs embedding and vectorstore
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
# retriever, LLM ì—°ê²°, QA chain êµ¬ì„±
from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate

# ========== RAG ê´€ë ¨ ìœ í‹¸ë¦¬í‹° ==========
@st.cache_resource
def load_drift_knowledge_base():
    """ë“œë¦¬í”„íŠ¸ ê¸°ìˆ  ë¬¸ì„œë¥¼ FAISS ë²¡í„° DBë¡œ ë¡œë“œ (LangChain í™œìš©)"""
    pdf_path = "pdf_db/datadrift_tech_docs.pdf"
    
    if not os.path.exists(pdf_path):
        st.warning(f"ë“œë¦¬í”„íŠ¸ ê¸°ìˆ  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return None, None
    
    try:
        # 1. PDF ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¶„í• 
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()
        
        # 2. í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        chunks = text_splitter.split_documents(documents)
        
        # 3. HuggingFace ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # 4. FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = FAISS.from_documents(chunks, embeddings)
        
        # 5. Ollama LLM ì„¤ì •
        llm = OllamaLLM(
            model="huihui_ai/exaone3.5-abliterated:7.8b",
            temperature=0.7
        )
        
        return vectorstore, llm
        
    except Exception as e:
        st.error(f"ë“œë¦¬í”„íŠ¸ ì§€ì‹ ë² ì´ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None



def search_drift_knowledge(query: str, top_k: int = 3):
    """ë“œë¦¬í”„íŠ¸ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ (LangChain í™œìš©)"""
    vectorstore, llm = load_drift_knowledge_base()
    
    if not all([vectorstore, llm]):
        return []
    
    try:
        # ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
        relevant_docs = vectorstore.similarity_search(query, k=top_k)
        
        # ë¬¸ì„œ ë‚´ìš©ë§Œ ì¶”ì¶œ
        relevant_chunks = [doc.page_content for doc in relevant_docs]
        
        return relevant_chunks
        
    except Exception as e:
        st.error(f"ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def generate_llm_drift_explanation(dataset_name: str) -> str:
    """Ollama LLMì„ í™œìš©í•œ ë“œë¦¬í”„íŠ¸ ê²°ê³¼ í•´ì„¤ ìƒì„±"""
    
    # 1. í˜„ì¬ ë“œë¦¬í”„íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
    drift_summary = st.session_state.get('drift_score_summary', '')
    
    # 2. ê°•í™”ëœ ì„ë² ë”© ì •ë³´ ìˆ˜ì§‘
    embedding_info = {}
    pca_analysis = {}
    
    # ê¸°ë³¸ ì„ë² ë”© ì •ë³´
    for key in ['train_embeddings', 'valid_embeddings', 'test_embeddings']:
        embeddings = st.session_state.get(key)
        if embeddings is not None:
            embedding_info[key] = {
                'shape': embeddings.shape,
                'mean': float(embeddings.mean()) if hasattr(embeddings, 'mean') else 'N/A',
                'std': float(embeddings.std()) if hasattr(embeddings, 'std') else 'N/A'
            }
    
    # PCA ë¶„ì„ ì •ë³´ ê°•í™”
    pca_dim = st.session_state.get('pca_selected_dim')
    if pca_dim:
        pca_analysis['selected_dimension'] = pca_dim
        
        # PCA ì¢Œí‘œ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
        train_pca = st.session_state.get('train_embeddings_pca')
        test_pca = st.session_state.get('test_embeddings_pca')
        
        if train_pca is not None and test_pca is not None:
            import numpy as np
            train_center = np.mean(train_pca, axis=0)
            test_center = np.mean(test_pca, axis=0)
            center_distance = np.linalg.norm(train_center - test_center)
            
            pca_analysis.update({
                'train_center': f"({train_center[0]:.3f}, {train_center[1]:.3f})",
                'test_center': f"({test_center[0]:.3f}, {test_center[1]:.3f})",
                'center_distance': f"{center_distance:.3f}"
            })
    
    if not drift_summary:
        return ''
    # 3. ë“œë¦¬í”„íŠ¸ ë©”íŠ¸ë¦­ ìƒì„¸ ë¶„ì„
    drift_metrics_analysis = {}
    if drift_summary:
        lines = drift_summary.split('\n')
        for line in lines:
            if 'score =' in line and 'drift =' in line:
                # ë©”íŠ¸ë¦­ë³„ ì ìˆ˜ ì¶”ì¶œ
                parts = line.split(':')
                if len(parts) >= 2:
                    metric_name = parts[0].strip('- ')
                    score_part = parts[1].split(',')[0].replace('score =', '').strip()
                    drift_part = parts[1].split(',')[1].replace('drift =', '').strip()
                    
                    try:
                        score_value = float(score_part)
                        drift_metrics_analysis[metric_name] = {
                            'score': score_value,
                            'drift_detected': drift_part,
                            'threshold_level': 'low' if score_value < 0.01 else 'medium' if score_value < 0.05 else 'high'
                        }
                    except:
                        pass
    
    # 4. ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
    search_queries = [
        f"MMD Wasserstein KL divergence interpretation",
        f"data drift analysis embedding",
        "drift detection threshold explanation",
        f"PCA dimension reduction drift analysis"
    ]
    
    # 5. ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
    knowledge_context = []
    for query in search_queries:
        relevant_chunks = search_drift_knowledge(query, top_k=2)
        knowledge_context.extend(relevant_chunks)
    
    # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
    knowledge_context = list(set(knowledge_context))[:3]  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
    
    # 6. êµ¬ì¡°í™”ëœ ì •ë³´ êµ¬ì„±
    context_text = "\n\n".join(knowledge_context)
    
    # ì„ë² ë”© ì •ë³´ í…ìŠ¤íŠ¸ êµ¬ì„±
    embedding_info_text = ""
    for key, info in embedding_info.items():
        if isinstance(info, dict):
            embedding_info_text += f"{key}: shape={info['shape']}, mean={info['mean']}, std={info['std']}\n"
        else:
            embedding_info_text += f"{key}: {info}\n"
    
    # PCA ë¶„ì„ í…ìŠ¤íŠ¸ êµ¬ì„±
    pca_info_text = ""
    if pca_analysis:
        for key, value in pca_analysis.items():
            pca_info_text += f"{key}: {value}\n"
    
    # ë©”íŠ¸ë¦­ ë¶„ì„ í…ìŠ¤íŠ¸ êµ¬ì„±
    metrics_info_text = ""
    for metric, analysis in drift_metrics_analysis.items():
        metrics_info_text += f"{metric}: score={analysis['score']}, level={analysis['threshold_level']}, drift={analysis['drift_detected']}\n"
    
    # 7. ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (4ë‹¨ê³„ êµ¬ì¡°)
    prompt_template = PromptTemplate(
        input_variables=["dataset_name", "embedding_info", "drift_summary", "context"],
        template="""ë‹¹ì‹ ì€ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 4ë‹¨ê³„ êµ¬ì¡°í™”ëœ ë“œë¦¬í”„íŠ¸ ë¶„ì„ í•´ì„¤ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

            ë°ì´í„°ì…‹ ì •ë³´:
            - ì´ë¦„: {dataset_name}
            - ì„ë² ë”© ì •ë³´: {embedding_info}
            - ë“œë¦¬í”„íŠ¸ ë¶„ì„ ê²°ê³¼: {drift_summary}

            ì°¸ê³  ì§€ì‹:
            {context}

            ì•„ë˜ì™€ ê°™ì´ 4ë‹¨ê³„ êµ¬ì¡°ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

            [ê¸°ìˆ ì  ë¶„ì„] ê° ë“œë¦¬í”„íŠ¸ ë©”íŠ¸ë¦­ì˜ ìˆ˜ì¹˜ì  ì˜ë¯¸ì™€ ì„ê³„ê°’ ëŒ€ë¹„ í•´ì„ì„ ì œì‹œí•©ë‹ˆë‹¤. MMD, Wasserstein, KL Divergence ë“±ì˜ ì ìˆ˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.

            [í˜„ ìƒí™© ë¶„ì„] í˜„ì¬ ë“œë¦¬í”„íŠ¸ ìƒí™©ì´ ëª¨ë¸ ì„±ëŠ¥ê³¼ ì„œë¹„ìŠ¤ ì•ˆì •ì„±ì— ë¯¸ì¹  ì˜í–¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì¬í•™ìŠµ í•„ìš”ì„±ê³¼ ìœ„í—˜ë„ë¥¼ íŒë‹¨í•˜ì„¸ìš”.

            [ì‹œê°ì  ë¶„ì„] PCA ì‹œê°í™” ê²°ê³¼ì™€ ì—°ê³„í•˜ì—¬ ë°ì´í„° ë¶„í¬ ë³€í™”ë¥¼ í•´ì„í•©ë‹ˆë‹¤. ê°€ëŠ¥í•˜ë‹¤ë©´ ì¤‘ì‹¬ì  ì´ë™ê³¼ ë¶„í¬ ê²¹ì¹¨ ì •ë„ë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”.

            [ê¶Œì¥ì‚¬í•­] ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­ê³¼ ëª¨ë‹ˆí„°ë§ ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì„ê³„ê°’ê³¼ ì‹¤í–‰ ê³„íšì„ í¬í•¨í•˜ì„¸ìš”.

            ê° ë‹¨ê³„ëŠ” ë°˜ë“œì‹œ ëŒ€ê´„í˜¸ë¡œ ì‹œì‘í•˜ë©°, 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , ì „ì²´ 500ì ë‚´ì™¸ë¡œ ì œí•œí•˜ì„¸ìš”.
    """
    )
    
    # RAG Input Variablesë¥¼ HTMLë¡œ í¬ë§·íŒ…
    input_variables_html = f"""
    <div class="rag-input-variables" style="background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 8px; padding: 20px; margin: 20px 0;">
        <h4 style="color: #495057; margin-bottom: 15px;">ğŸ” RAG ë¶„ì„ ì…ë ¥ ë³€ìˆ˜</h4>
        
        <div style="margin-bottom: 15px;">
            <h5 style="color: #007bff; margin-bottom: 8px;">ğŸ“Š Dataset Information</h5>
            <pre style="background-color: white; padding: 10px; border-radius: 4px; border: 1px solid #dee2e6; margin: 0;">{dataset_name}</pre>
        </div>
        
        <div style="margin-bottom: 15px;">
            <h5 style="color: #28a745; margin-bottom: 8px;">ğŸ¯ Embedding Information</h5>
            <pre style="background-color: white; padding: 10px; border-radius: 4px; border: 1px solid #dee2e6; margin: 0; max-height: 150px; overflow-y: auto;">{embedding_info_text}</pre>
        </div>
              
        <div style="margin-bottom: 15px;">
            <h5 style="color: #6f42c1; margin-bottom: 8px;">ğŸ“‹ Drift Summary</h5>
            <pre style="background-color: white; padding: 10px; border-radius: 4px; border: 1px solid #dee2e6; margin: 0; max-height: 120px; overflow-y: auto;">{drift_summary}</pre>
        </div>
    </div>
    """
    
    # 8. Ollama LLM í˜¸ì¶œ
    try:
        vectorstore, llm = load_drift_knowledge_base()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        formatted_prompt = prompt_template.format(
            dataset_name=dataset_name,
            embedding_info=embedding_info_text,
            pca_info=pca_info_text,
            metrics_info=metrics_info_text,
            drift_summary=drift_summary,
            context=context_text
        )
        
        # LLM í˜¸ì¶œ
        explanation = llm.invoke(formatted_prompt)
        
        # HTML í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (êµ¬ì¡°í™”ëœ ìŠ¤íƒ€ì¼ë§)
        formatted_explanation = format_structured_explanation(explanation)
        
        return f"""
        {input_variables_html}
        <div class="comment-box" style="background-color: #e8f5e8; border-left: 4px solid #28a745; padding: 20px; margin: 10px 0;">
            <h4 style="margin-top: 0; color: #28a745;">ğŸ¤– AI ë°ì´í„° ë“œë¦¬í”„íŠ¸ ë¶„ì„ í•´ì„¤</h4>
            <div style="line-height: 1.8; font-size: 14px;">
                {formatted_explanation}
            </div>
            <small style="color: #6c757d; font-style: italic; margin-top: 15px; display: block;">
                * ì´ í•´ì„¤ì€ ë¡œì»¬ AI(Ollama)ê°€ ê¸°ìˆ  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±í•œ ê²ƒì…ë‹ˆë‹¤.
            </small>
        </div>
        """
        
    except Exception as e:
        st.warning(f"AI í•´ì„¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return 

def format_structured_explanation(explanation: str) -> str:
    """LLM ì‘ë‹µì„ êµ¬ì¡°í™”ëœ HTMLë¡œ ë³€í™˜"""
    
    # 4ë‹¨ê³„ ì„¹ì…˜ ìŠ¤íƒ€ì¼ ì •ì˜
    section_styles = {
        'ê¸°ìˆ ì  ë¶„ì„': 'background-color: #f8f9fa; border-left: 3px solid #007bff; color: #0056b3;',
        'ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸': 'background-color: #fff3cd; border-left: 3px solid #ffc107; color: #856404;',
        'ì‹œê°ì  ë¶„ì„': 'background-color: #d1ecf1; border-left: 3px solid #17a2b8; color: #0c5460;',
        'ê¶Œì¥ì‚¬í•­': 'background-color: #d4edda; border-left: 3px solid #28a745; color: #155724;'
    }
    
    # ëŒ€ê´„í˜¸ë¡œ ì‹œì‘í•˜ëŠ” ì„¹ì…˜ ì°¾ê¸°
    pattern = r'\[([^\]]+)\]\s*(.*?)(?=\[|$)'
    matches = re.findall(pattern, explanation, re.DOTALL)
    
    if not matches:
        # êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ì‘ë‹µì¸ ê²½ìš° ê¸°ë³¸ í¬ë§·íŒ…
        return explanation.replace('\n', '<br>')
    
    formatted_html = ""
    for section_title, content in matches:
        section_title = section_title.strip()
        content = content.strip()
        
        # í•´ë‹¹ ì„¹ì…˜ ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°
        style = section_styles.get(section_title, 'background-color: #f8f9fa; border-left: 3px solid #6c757d; color: #495057;')
        
        # HTML ì„¹ì…˜ êµ¬ì„±
        formatted_html += f"""
        <div style="margin: 15px 0; padding: 15px; border-radius: 5px; {style}">
            <h5 style="margin: 0 0 10px 0; font-weight: bold;">ğŸ“‹ {section_title}</h5>
            <p style="margin: 0; line-height: 1.6;">{content}</p>
        </div>
        """
    
    return formatted_html