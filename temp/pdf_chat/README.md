## âœ”ï¸Â **Overview**

---

### Main point.

```mermaid
graph TD
    A["PDF ì—…ë¡œë“œ"] --> B["í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¶„í• "]
    B --> C["ì„ë² ë”©<br>(HuggingFace)"]
    C --> D["Milvus ë²¡í„° ì €ì¥"]
    D --> E["RetrievalQA ì²´ì¸"]
    E --> F["ë¡œì»¬ LLM <br> (LlamaCpp)"]
    F --> H["ì‘ë‹µ ìƒì„±"]
    F --> G["Streamlit UIë¡œ ì¶œë ¥ <br> ë° íˆìŠ¤í† ë¦¬ ì €ì¥"]

```

* LLM API ë¯¸ì‚¬ìš© â†’ ë¹„ìš© ì—†ì´ ë¡œì»¬ì—ì„œ ì¶”ë¡  ê°€ëŠ¥

### Main tech.

**LangChain**

- ë¬¸ì„œ ë¡œë”© ë° ë¶„í• 
    - í…ìŠ¤íŠ¸ ì¶”ì¶œ : `PyPDFLoader`
    - ì²­í¬ ë‹¨ìœ„ ë¶„í•  : `RecursiveCharacterTextSplitter`
- ì„ë² ë”© ë° ë²¡í„° ì €ì¥
    - Embedding Model : Hugging Face ì„ë² ë”© ëª¨ë¸ `sentence-transformers/all-MiniLM-L6-v2`
    - Vector DB : Milvus
    - RAG : `vectorstore.as_retriever()`

**Llama cpp**

ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” GGUF í¬ë§· ëª¨ë¸ ì‚¬ìš©í•´ `llama-cpp-python`ì„ í†µí•´ LangChainê³¼ ì—°ê²°

- ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ GPU ì—†ì´ë„ ë¡œì»¬ ì¶”ë¡  ê°€ëŠ¥
    - ğŸš€ [ggml-model-Q4_K_M.gguf](https://huggingface.co/heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF/blob/main/ggml-model-Q4_K_M.gguf) ; ë¡œì»¬ì— ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í›„, ê²½ë¡œ ì§€ì • í•„ìš”
- LLM ì¶”ë¡ ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥

**Streamlit**

ì‚¬ìš©ì ì¹œí™”ì ì¸ Chatbot í˜•íƒœ ì¸í„°í˜ì´ìŠ¤ë¡œ `streamlit_chat` ìœ¼ë¡œ ëŒ€í™”í˜• UI êµ¬ì„±

- Full Flow
    1. íŒŒì¼ ì—…ë¡œë“œ ë° ìë™ ì²˜ë¦¬ (PDF â†’ í…ìŠ¤íŠ¸ â†’ ì„ë² ë”©)
    2. ì§ˆë¬¸ ì…ë ¥ â†’ ì‘ë‹µ ìƒì„± (LangChain QA ì²´ì¸ í™œìš©)
    3. ì´ì „ ëŒ€í™” ë‚´ìš©ì€ `st.session_state`ë¥¼ í†µí•´ íˆìŠ¤í† ë¦¬ ê´€ë¦¬

### **Project Goals.**

- [x]  pdf ì—…ë¡œë“œ í›„, íƒìƒ‰í•´ ì›í•˜ëŠ” ë‹µë³€ì„ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆëŠ”ì§€
- [ ]  (ì˜ˆì •) [multiturn chatbot](https://flyduckdev.tistory.com/entry/Rag-OpenAI-RAG-%EA%B8%B0%EB%B0%98-%EC%98%A4%EB%A7%8C%EA%B3%BC-%ED%8E%B8%EA%B2%AC-%EC%B1%97%EB%B4%87-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0-LangChain-OpenAI-Streamlit) êµ¬í˜„
- [ ]  (ì˜ˆì •) optionìœ¼ë¡œ ì—¬ëŸ¬ ëª¨ë¸ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ë„ì…
- [ ]  (ì˜ˆì •) RAG ì ìš© ë° êµ¬í˜„

## âœ”ï¸Â Installation

---

1. Clone thie Repository
    
    ```bash
    git clone https://github.com/jeongminia/datadrift_dataclinic.git
    ```
    
2. Navigate to the project directory
    
    ```bash
    # dir : datadrift_dataclinic/temp/pdf_chat/main.py
    cd temp/pdf_chat
    ```
    
3. Install libraries
    
    ```bash
    # (option) virtual environment
    python -m venv chatenv
    source chatenv/bin/activate  # Mac/Linux
    ```
    
    ```bash
    pip install -r requirements.txt
    ```
    
    - llama-cpp-python(cuda)
        - ì¶”ê°€ ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ì§€ ì•Šìœ¼ë©´ modelì´ cpuì—ì„œë§Œ ëŒì•„ê°€ì„œ ë§ì€ ì‹œê°„ì´ ì†Œìš”
        - CUDA ì˜µì…˜ì„ í™œì„±í™”í•´ì„œ ì§ì ‘ ë¹Œë“œ
        1. ì˜ì¡´ íŒ¨í‚¤ì§€ ì„¤ì¹˜
            
            ```bash
            sudo apt update
            sudo apt install build-essential cmake
            pip install setuptools wheel ninja
            ```
            
        2. install llama-cpp-python 
            
            ```bash
            CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python --no-binary llama-cpp-python
            ```
            
            - `-DLLAMA_CUBLAS=on` : GPUìš© CUDA CUBLAS ë°±ì—”ë“œ í™œì„±í™”
            - `FORCE_CMAKE=1` : í•­ìƒ ìƒˆë¡œ ë¹Œë“œ
            - `-no-binary` : PyPI wheel ë¬´ì‹œí•˜ê³  ì†ŒìŠ¤ì—ì„œ ì§ì ‘ ì»´íŒŒì¼

## âœ”ï¸Â **Usage**

---

1. Streamlit ì‹¤í–‰
    
    ```bash
    streamlit run main.py
    ```
    
2. UI í†µí•´ì„œ PDF ì—…ë¡œë“œ
    - Limit 200MB per file â€¢ PDF, TXT, DOCX
3. ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ ì‹œ, ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì§ˆë¬¸ ì±—ì— ì…ë ¥
4. Streamlit ì¤‘ë‹¨
    - (mac)Â `pkill -f streamlit`

## âœ”ï¸Â References

---

https://wikidocs.net/231360

https://flyduckdev.tistory.com/entry/RAG-%EA%B8%B0%EB%B0%98-Chat-PDF-%EC%B1%97%EB%B4%87-%EB%A7%8C%EB%93%A4%EA%B8%B0-LangChain-Cohere-OpenAI-API%EB%A1%9C-%EB%82%98%EB%A7%8C%EC%9D%98-%EB%AC%B8%EC%84%9C-%EC%A7%88%EB%AC%B8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%A7%8C%EB%93%A4%EA%B8%B0