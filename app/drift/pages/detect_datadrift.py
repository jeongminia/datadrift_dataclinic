import os
import numpy as np
import pandas as pd 
import streamlit as st
import matplotlib.pyplot as plt
import json
from pymilvus import Collection, utility

# Detect DataDrift
from evidently.metrics import EmbeddingsDriftMetric
from evidently.report import Report
from evidently.metrics.data_drift.embedding_drift_methods import mmd
from evidently.metrics.data_drift.embedding_drift_methods import ratio
from evidently import ColumnMapping
import streamlit.components.v1 as components  # HTML ì—´ë¡ ë§ì„ ìœ„í•œ Streamlit ì»¨í¼ëŸ°íŠ¸

# HTML ì €ì¥ ê²½ë¡œ ì„¤ì •
HTML_SAVE_PATH = "reports"

# reports ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
if not os.path.exists(HTML_SAVE_PATH):
    os.makedirs(HTML_SAVE_PATH)

#  --------------------------------------------- Update Drift Metadata ---------------------------------------------
def update_metadata_to_vectordb(dataset_name):
    """ë“œë¦¬í”„íŠ¸ ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ Milvus Collectionì— ì—…ë°ì´íŠ¸"""
    try:
        if not utility.has_collection(dataset_name):
            st.error(f"Collection '{dataset_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None
            
        collection = Collection(name=dataset_name)
        collection.load()
        
        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        metadata_results = collection.query(
            expr="set_type == 'metadata'",
            output_fields=["id", "dataset_name", "summary_dict", "data_previews", "class_dist_path",
                          "doc_len_path", "doc_len_table", "wordcloud_path", "timestamp"],
            limit=1
        )
        
        if not metadata_results:
            st.error("ê¸°ì¡´ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        existing_metadata = metadata_results[0]
        metadata_id = existing_metadata["id"]
        
        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì‚­ì œ
        collection.delete(f"id == {metadata_id}")
        collection.flush()
        
        # ì„¸ì…˜ì—ì„œ ë“œë¦¬í”„íŠ¸ ê´€ë ¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        embedding_size = st.session_state.get("embedding_overview_text", "")
        dimension = float(st.session_state.get("selected_dimension", 0))  # selected_dimension ì‚¬ìš©
        drift_score_summary = st.session_state.get("drift_score_summary", "")
        original_distance_path = st.session_state.get("original_distance_path", "")
        pca_distance_path = st.session_state.get("PCA_distance_path", "")
        pca_visualization_path = st.session_state.get("PCA_visualization_path", "")
        
        # ìƒˆ ë©”íƒ€ë°ì´í„° ì‚½ì… (ê¸°ì¡´ ë°ì´í„° + ë“œë¦¬í”„íŠ¸ ë°ì´í„°)
        dummy_vector = [0.0] * 768
        
        data = [
            ["metadata"],                                    # set_type
            ["metadata"],                                    # class
            [dummy_vector],                                  # vector
            [existing_metadata["dataset_name"]],            # dataset_name
            [existing_metadata["summary_dict"]],            # summary_dict
            [existing_metadata["data_previews"]],           # data_previews
            [existing_metadata["class_dist_path"]],         # class_dist_path
            [existing_metadata["doc_len_path"]],            # doc_len_path
            [existing_metadata["doc_len_table"]],           # doc_len_table
            [existing_metadata["wordcloud_path"]],          # wordcloud_path
            [existing_metadata["timestamp"]],               # timestamp
            # ë°ì´í„° ë“œë¦¬í”„íŠ¸ í•„ë“œë“¤ ì—…ë°ì´íŠ¸
            [dimension],                                     # dimension
            [embedding_size],                                # embedding_size
            [original_distance_path],                        # original_distance_path
            [pca_distance_path],                            # PCA_distance_path
            [pca_visualization_path],                       # PCA_visualization_path
            [drift_score_summary],                          # drift_score_summary
        ]
        
        fields = ["set_type", "class", "vector", "dataset_name", "summary_dict", 
                 "data_previews", "class_dist_path", "doc_len_path", "doc_len_table", 
                 "wordcloud_path", "timestamp", "dimension", "embedding_size", 
                 "original_distance_path", "PCA_distance_path", "PCA_visualization_path", 
                 "drift_score_summary"]
        
        result = collection.insert(data, fields=fields)
        collection.flush()
        
        st.success("âœ… ë°ì´í„° ë“œë¦¬í”„íŠ¸ ë©”íƒ€ë°ì´í„°ê°€ ë²¡í„°DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return result.primary_keys[0]
        
    except Exception as e:
        st.error(f"âŒ ë“œë¦¬í”„íŠ¸ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return None


#  --------------------------------------------- Main ---------------------------------------------
def render():
    dataset_name = st.session_state.get('dataset_name')
    # st.title(f"Detect {dataset_name} DataDrift Page")

    if 'train_embeddings' not in st.session_state or 'valid_embeddings' not in st.session_state or 'test_embeddings' not in st.session_state:
        st.error("Embeddings are not available. Please generate embeddings in the 'Embedding Visualization' tab first.")
        return

    train_embeddings = st.session_state['train_embeddings']
    valid_embeddings = st.session_state['valid_embeddings']
    test_embeddings = st.session_state['test_embeddings']

    # ë°ì´í„° í˜•ì‹ í™•ì¸ ë° ë³€í™˜
    if not isinstance(train_embeddings, np.ndarray):
        train_embeddings = np.array(train_embeddings)
    if not isinstance(valid_embeddings, np.ndarray):
        valid_embeddings = np.array(valid_embeddings)
    if not isinstance(test_embeddings, np.ndarray):
        test_embeddings = np.array(test_embeddings)

    # PCA ì ìš©ëœ ì„ë² ë”©ì´ ìˆìœ¼ë©´ ì‚¬ìš© (embedding_visualizationì—ì„œ ìƒì„±ëœ ê²ƒ)
    if ('train_embeddings_pca' in st.session_state and 
        'test_embeddings_pca' in st.session_state and
        'selected_dimension' in st.session_state):

        train_embeddings = st.session_state['train_embeddings_pca']
        test_embeddings = st.session_state['test_embeddings_pca']
        selected_dim = st.session_state['selected_dimension']
        st.info(f"ğŸ¯ Using PCA-reduced embeddings from Visualization page (Dimension: {selected_dim})")
    else:
        st.warning("âš ï¸ Using original embeddings. Please visit Embedding Visualization page first to apply dimension reduction.")

    # evidentlyai - ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê²€ì‚¬
    st.write("Train(reference)-Test(current) Data Drift Detection")
    reference_df = pd.DataFrame(train_embeddings, 
                                columns=[f"dim_{i}" for i in range(train_embeddings.shape[1])])
    current_df = pd.DataFrame(test_embeddings, 
                              columns=[f"dim_{i}" for i in range(test_embeddings.shape[1])])

    column_mapping = ColumnMapping(
        embeddings={'all_dimensions': reference_df.columns.tolist()}
    )

    # embedding_loadì—ì„œ ì„ íƒëœ í…ŒìŠ¤íŠ¸ íƒ€ì… ì‚¬ìš©
    if 'selected_test_type' in st.session_state:
        test_option = st.session_state['selected_test_type']
        st.success(f"âœ… Using test type setting from Load page: **{test_option}**")
        st.write(f"Current test method: {test_option}")
    else:
        # ê¸°ë³¸ê°’ ì„¤ì • (Load í˜ì´ì§€ì—ì„œ ì„¤ì •í•˜ì§€ ì•Šì€ ê²½ìš°)
        test_option = st.selectbox("Select Test Type", 
                                   ["MMD", "Wasserstein Distance", 
                                    "KL Divergence", "JensenShannon Divergence", 
                                    "Energy Distance"])
        st.warning("âš ï¸ Test type not set in Load page. Using local selection.")

    test_methods = {
        "MMD": mmd(threshold=0.015),
        "Wasserstein Distance": ratio(component_stattest='wasserstein', component_stattest_threshold=0.1, threshold=0.015),
        "KL Divergence": ratio(component_stattest='kl_div', component_stattest_threshold=0.1, threshold=0.015),
        "JensenShannon Divergence": ratio(component_stattest='jensenshannon', component_stattest_threshold=0.1, threshold=0.015),
        "Energy Distance": ratio(component_stattest='ed', component_stattest_threshold=0.1, threshold=0.015),
    }

    # ëŒ€ì‹œë³´ë“œìš© Report ìƒì„± ë° ì €ì¥
    selected_method = test_methods[test_option]
    visual_report = Report(metrics=[EmbeddingsDriftMetric('all_dimensions', drift_method=selected_method)])
    visual_report.run(reference_data=reference_df, current_data=current_df, column_mapping=column_mapping)

    html_path = os.path.join(HTML_SAVE_PATH, f"{dataset_name}_drift_report.html")
    visual_report.save_html(html_path)
    with open(html_path, "r") as f:
        st.session_state['drift_report_html'] = f.read()

    # ëª¨ë“  ë°©ë²•ì— ëŒ€í•œ ë“œë¦¬í”„íŠ¸ ì ìˆ˜ ìš”ì•½ ì €ì¥
    drift_summary = []
    for name, method in test_methods.items():
        try:
            temp_report = Report(metrics=[EmbeddingsDriftMetric('all_dimensions', drift_method=method)])
            temp_report.run(reference_data=reference_df, current_data=current_df, column_mapping=column_mapping)
            result = temp_report.as_dict().get("metrics", [])[0].get("result", {})
            score = result.get("drift_score", "N/A")
            detected = result.get("drift_detected", "N/A")
            drift_summary.append(f"- {name}: score = {score:.4f}, drift = {detected}")
        except Exception as e:
            drift_summary.append(f"- {name}: failed ({e})")

    summary_text = "\n".join(drift_summary)
    st.session_state['drift_score_summary'] = summary_text

    # Streamlit ë‚´ HTML ì‹œê°í™”
    components.html(st.session_state['drift_report_html'], height=800, scrolling=True, width=1600)
    st.success("âœ… Drift report & all scores saved in session_state.")
    
    # ë“œë¦¬í”„íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ ë²¡í„°DBì— ì—…ë°ì´íŠ¸
    with st.spinner("ğŸ’¾ Saving drift results to database..."):
        result = update_metadata_to_vectordb(dataset_name)
        if result:
            st.info("ğŸ” Drift analysis results have been automatically saved to the vector database.")
        else:
            st.warning("âš ï¸ Failed to save drift results to database.")